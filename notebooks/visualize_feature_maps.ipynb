{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IcjFH5JFEOc"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"resnet34-cifar10-feature-maps\", config={\"epochs\": 10, \"batch_size\": 64, \"learning_rate\": 0.001})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet34\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Configuration\n",
        "config = wandb.config\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define model, loss function, and optimizer\n",
        "model = resnet34(pretrained=False, num_classes=10)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "# Helper functions to log kernels to wandb\n",
        "def log_kernels_to_wandb(layer, layer_name, epoch):\n",
        "    kernels = layer.weight.data.cpu().numpy()\n",
        "    num_kernels = kernels.shape[0]\n",
        "    num_channels = kernels.shape[1]\n",
        "\n",
        "    # Normalize kernels to [0, 1] for visualization\n",
        "    kernels = (kernels - kernels.min()) / (kernels.max() - kernels.min())\n",
        "\n",
        "    # Calculate grid size\n",
        "    num_cols = int(np.ceil(np.sqrt(num_kernels)))\n",
        "    num_rows = int(np.ceil(num_kernels / num_cols))\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))\n",
        "    axes = axes.flatten()  # Flatten to easily iterate and avoid index issues\n",
        "\n",
        "    for i in range(num_kernels):\n",
        "        kernel = kernels[i]\n",
        "        if num_channels == 3:  # RGB kernel\n",
        "            kernel = kernel.transpose(1, 2, 0)\n",
        "        axes[i].imshow(kernel, cmap=\"viridis\")\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    # Turn off any remaining empty subplots\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    fig.suptitle(f\"{layer_name} Kernels at Epoch {epoch}\")\n",
        "    wandb.log({f\"{layer_name}_kernels\": wandb.Image(fig)})\n",
        "    plt.close(fig)\n",
        "\n",
        "# Helper function to visualize and log activation maps to wandb\n",
        "def visualize_activation_maps(model, layer_name, input_image, epoch):\n",
        "    activation = {}\n",
        "\n",
        "    def hook_fn(module, input, output):\n",
        "        activation[layer_name] = output.detach()\n",
        "\n",
        "    layer = dict([*model.named_modules()])[layer_name]\n",
        "    hook = layer.register_forward_hook(hook_fn)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        _ = model(input_image.unsqueeze(0).to(device))\n",
        "\n",
        "    hook.remove()\n",
        "\n",
        "    # Get the activation maps and check shape\n",
        "    act_maps = activation[layer_name].squeeze().cpu()\n",
        "\n",
        "    # Ensure act_maps has at least 2 dimensions (height, width) per map\n",
        "    if act_maps.dim() == 1:\n",
        "        # If it’s 1D, there's nothing to display as an image\n",
        "        print(f\"Layer {layer_name} produced 1D outputs; cannot display.\")\n",
        "        return\n",
        "    elif act_maps.dim() == 2:\n",
        "        # If 2D, we assume it's already in [height, width] format for a single map\n",
        "        act_maps = act_maps.unsqueeze(0)  # Add dimension to handle it as a single-channel map\n",
        "\n",
        "    num_maps = act_maps.size(0)  # Number of channels or feature maps\n",
        "    num_cols = int(np.ceil(np.sqrt(num_maps)))\n",
        "    num_rows = int(np.ceil(num_maps / num_cols))\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(num_maps):\n",
        "        axes[i].imshow(act_maps[i], cmap=\"viridis\")\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    # Turn off any unused axes\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    fig.suptitle(f\"{layer_name} Activation Maps at Epoch {epoch}\")\n",
        "    wandb.log({f\"{layer_name}_activation_maps\": wandb.Image(fig)})\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(config.epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Log every 100 mini-batches\n",
        "        if i % 100 == 99:\n",
        "            avg_loss = running_loss / 100\n",
        "            wandb.log({\"epoch\": epoch + 1, \"loss\": avg_loss})\n",
        "            print(f\"[Epoch {epoch+1}, Batch {i+1}] Loss: {avg_loss:.4f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Save and log kernels for low-level and high-level features\n",
        "    if epoch % 1 == 0:  # Log every epoch\n",
        "        log_kernels_to_wandb(model.conv1, \"Low_Level_Features\", epoch + 1)\n",
        "        log_kernels_to_wandb(model.layer4[0].conv1, \"High_Level_Features\", epoch + 1)  # Example of a high-level layer\n",
        "\n",
        "    # Visualize and log activation maps for a sample image\n",
        "\n",
        "    # Visualize and log activation maps for a sample image\n",
        "    sample_img = sample_img.to(device)\n",
        "\n",
        "    visualize_activation_maps(model, \"layer1.0.conv1\", sample_img, epoch + 1)  # Example low-level activation map\n",
        "    visualize_activation_maps(model, \"layer4.0.conv1\", sample_img, epoch + 1)  # Example high-level activation map\n",
        "\n",
        "# Testing the model and logging accuracy\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "wandb.log({\"test_accuracy\": accuracy})\n",
        "print(\"Test Accuracy: {:.2f}%\".format(accuracy))\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I9Z8ocQ-mNJH",
        "outputId": "57aa7ac1-6efd-48b7-a873-96c38d4c41bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:8ktxmheg) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▅▄▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>1.4078</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">golden-spaceship-10</strong> at: <a href='https://wandb.ai/aneuralresearch/resnet34-cifar10/runs/8ktxmheg' target=\"_blank\">https://wandb.ai/aneuralresearch/resnet34-cifar10/runs/8ktxmheg</a><br/> View project at: <a href='https://wandb.ai/aneuralresearch/resnet34-cifar10' target=\"_blank\">https://wandb.ai/aneuralresearch/resnet34-cifar10</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241114_122431-8ktxmheg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:8ktxmheg). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241114_123536-a2pu1nl4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aneuralresearch/resnet34-cifar10/runs/a2pu1nl4' target=\"_blank\">hopeful-sponge-11</a></strong> to <a href='https://wandb.ai/aneuralresearch/resnet34-cifar10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aneuralresearch/resnet34-cifar10' target=\"_blank\">https://wandb.ai/aneuralresearch/resnet34-cifar10</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aneuralresearch/resnet34-cifar10/runs/a2pu1nl4' target=\"_blank\">https://wandb.ai/aneuralresearch/resnet34-cifar10/runs/a2pu1nl4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[Epoch 1, Batch 100] Loss: 2.0758\n",
            "[Epoch 1, Batch 200] Loss: 1.7921\n",
            "[Epoch 1, Batch 300] Loss: 1.6708\n",
            "[Epoch 1, Batch 400] Loss: 1.6245\n",
            "[Epoch 1, Batch 500] Loss: 1.5623\n",
            "[Epoch 1, Batch 600] Loss: 1.4773\n",
            "[Epoch 1, Batch 700] Loss: 1.4565\n",
            "Layer layer4.0.conv1 produced 1D outputs; cannot display.\n",
            "[Epoch 2, Batch 100] Loss: 1.3883\n",
            "[Epoch 2, Batch 200] Loss: 1.3265\n",
            "[Epoch 2, Batch 300] Loss: 1.2894\n",
            "[Epoch 2, Batch 400] Loss: 1.2392\n",
            "[Epoch 2, Batch 500] Loss: 1.2242\n",
            "[Epoch 2, Batch 600] Loss: 1.1964\n",
            "[Epoch 2, Batch 700] Loss: 1.1686\n",
            "Layer layer4.0.conv1 produced 1D outputs; cannot display.\n",
            "[Epoch 3, Batch 100] Loss: 1.1279\n",
            "[Epoch 3, Batch 200] Loss: 1.0594\n",
            "[Epoch 3, Batch 300] Loss: 1.0989\n",
            "[Epoch 3, Batch 400] Loss: 1.0933\n",
            "[Epoch 3, Batch 500] Loss: 1.0567\n",
            "[Epoch 3, Batch 600] Loss: 1.0670\n",
            "[Epoch 3, Batch 700] Loss: 1.0470\n",
            "Layer layer4.0.conv1 produced 1D outputs; cannot display.\n",
            "[Epoch 4, Batch 100] Loss: 1.0446\n",
            "[Epoch 4, Batch 200] Loss: 0.9793\n",
            "[Epoch 4, Batch 300] Loss: 1.0515\n",
            "[Epoch 4, Batch 400] Loss: 0.9843\n",
            "[Epoch 4, Batch 500] Loss: 0.9627\n",
            "[Epoch 4, Batch 600] Loss: 0.9683\n",
            "[Epoch 4, Batch 700] Loss: 0.9383\n",
            "Layer layer4.0.conv1 produced 1D outputs; cannot display.\n",
            "[Epoch 5, Batch 100] Loss: 0.9706\n",
            "[Epoch 5, Batch 200] Loss: 0.9506\n",
            "[Epoch 5, Batch 300] Loss: 0.9070\n",
            "[Epoch 5, Batch 400] Loss: 0.8805\n",
            "[Epoch 5, Batch 500] Loss: 0.8753\n",
            "[Epoch 5, Batch 600] Loss: 0.8480\n",
            "[Epoch 5, Batch 700] Loss: 0.8469\n",
            "Layer layer4.0.conv1 produced 1D outputs; cannot display.\n",
            "[Epoch 6, Batch 100] Loss: 0.8780\n",
            "[Epoch 6, Batch 200] Loss: 0.9424\n",
            "[Epoch 6, Batch 300] Loss: 0.8926\n",
            "[Epoch 6, Batch 400] Loss: 0.8229\n",
            "[Epoch 6, Batch 500] Loss: 0.8059\n",
            "[Epoch 6, Batch 600] Loss: 0.8029\n",
            "[Epoch 6, Batch 700] Loss: 0.7972\n",
            "Layer layer4.0.conv1 produced 1D outputs; cannot display.\n",
            "[Epoch 7, Batch 100] Loss: 0.7598\n",
            "[Epoch 7, Batch 200] Loss: 0.7719\n",
            "[Epoch 7, Batch 300] Loss: 0.7774\n",
            "[Epoch 7, Batch 400] Loss: 0.7501\n",
            "[Epoch 7, Batch 500] Loss: 0.8020\n",
            "[Epoch 7, Batch 600] Loss: 0.7740\n",
            "[Epoch 7, Batch 700] Loss: 0.7951\n",
            "Layer layer4.0.conv1 produced 1D outputs; cannot display.\n",
            "[Epoch 8, Batch 100] Loss: 0.7312\n",
            "[Epoch 8, Batch 200] Loss: 0.7201\n",
            "[Epoch 8, Batch 300] Loss: 0.7841\n",
            "[Epoch 8, Batch 400] Loss: 0.7971\n",
            "[Epoch 8, Batch 500] Loss: 0.7921\n",
            "[Epoch 8, Batch 600] Loss: 0.7280\n",
            "[Epoch 8, Batch 700] Loss: 0.8946\n",
            "Layer layer4.0.conv1 produced 1D outputs; cannot display.\n",
            "[Epoch 9, Batch 100] Loss: 0.7469\n",
            "[Epoch 9, Batch 200] Loss: 0.8539\n",
            "[Epoch 9, Batch 300] Loss: 0.7530\n",
            "[Epoch 9, Batch 400] Loss: 0.7071\n",
            "[Epoch 9, Batch 500] Loss: 0.6837\n",
            "[Epoch 9, Batch 600] Loss: 0.6954\n",
            "[Epoch 9, Batch 700] Loss: 0.6811\n",
            "Layer layer4.0.conv1 produced 1D outputs; cannot display.\n",
            "[Epoch 10, Batch 100] Loss: 0.7316\n",
            "[Epoch 10, Batch 200] Loss: 0.7625\n",
            "[Epoch 10, Batch 300] Loss: 0.7502\n",
            "[Epoch 10, Batch 400] Loss: 0.6838\n",
            "[Epoch 10, Batch 500] Loss: 0.6659\n",
            "[Epoch 10, Batch 600] Loss: 0.6462\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}